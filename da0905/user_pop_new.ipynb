{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded exp0901/data/sample100/user_song_dt_000000000000.csv to ../data/exp0901/sample100/raw/user_song_dt_000000000000.csv.\n",
      "Downloaded exp0901/data/sample100/user_song_dt_000000000001.csv to ../data/exp0901/sample100/raw/user_song_dt_000000000001.csv.\n",
      "Downloaded exp0901/data/sample100/user_song_dt_000000000002.csv to ../data/exp0901/sample100/raw/user_song_dt_000000000002.csv.\n",
      "Downloaded exp0901/data/sample100/user_song_dt_000000000003.csv to ../data/exp0901/sample100/raw/user_song_dt_000000000003.csv.\n",
      "Downloaded exp0901/data/sample100/user_song_dt_000000000004.csv to ../data/exp0901/sample100/raw/user_song_dt_000000000004.csv.\n",
      "Downloaded exp0901/data/sample100/user_song_dt_000000000005.csv to ../data/exp0901/sample100/raw/user_song_dt_000000000005.csv.\n",
      "Downloaded exp0901/data/sample100/user_song_dt_000000000006.csv to ../data/exp0901/sample100/raw/user_song_dt_000000000006.csv.\n",
      "Downloaded exp0901/data/sample100/song_normalized_data_000000000000.csv to ../data/exp0901/sample100/raw/song_normalized_data_000000000000.csv.\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import storage\n",
    "import os\n",
    "\n",
    "def download_blob(bucket_name, source_blob_name, destination_file_name):\n",
    "    \"\"\"Downloads a blob from the bucket.\"\"\"\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    blob = bucket.blob(source_blob_name)\n",
    "\n",
    "    blob.download_to_filename(destination_file_name)\n",
    "\n",
    "    print(f\"Downloaded {source_blob_name} to {destination_file_name}.\")\n",
    "\n",
    "# Example usage\n",
    "bucket_name = \"leo_melon_simple\"\n",
    "blobs_to_download = [\n",
    "    \"exp0901/data/sample100/user_song_dt_000000000000.csv\",\n",
    "    \"exp0901/data/sample100/user_song_dt_000000000001.csv\",\n",
    "    \"exp0901/data/sample100/user_song_dt_000000000002.csv\",\n",
    "    \"exp0901/data/sample100/user_song_dt_000000000003.csv\",\n",
    "    \"exp0901/data/sample100/user_song_dt_000000000004.csv\",\n",
    "    \"exp0901/data/sample100/user_song_dt_000000000005.csv\",\n",
    "    \"exp0901/data/sample100/user_song_dt_000000000006.csv\",# Replace with your actual file paths\n",
    "    \"exp0901/data/sample100/song_normalized_data_000000000000.csv\"\n",
    "]\n",
    "destination_folder = \"../data/exp0901/sample100/raw\"  # Replace with the local folder path\n",
    "\n",
    "# Ensure the destination folder exists\n",
    "if not os.path.exists(destination_folder):\n",
    "    os.makedirs(destination_folder)\n",
    "\n",
    "for blob_name in blobs_to_download:\n",
    "    # Create the full local path for each file\n",
    "    destination_file_path = os.path.join(destination_folder, os.path.basename(blob_name))\n",
    "    # Download the file from GCS\n",
    "    download_blob(bucket_name, blob_name, destination_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "fd = \"../data/exp0901/sample100/raw\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [f\"{fd}/{f}\" for f in os.listdir(fd)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "usd_df = pd.concat([pd.read_csv(f, header=0) for f in files if \"user_song_dt\" in f])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40027,)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(usd_df.user_id).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "snd_df = pd.read_csv(f\"{fd}/song_normalized_data_000000000000.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         4.997058e-04\n",
       "1         2.785971e-04\n",
       "2         3.494983e-04\n",
       "3         3.385541e-05\n",
       "4         4.209286e-05\n",
       "              ...     \n",
       "338750    6.377706e-07\n",
       "338751    1.354216e-06\n",
       "338752    9.308733e-06\n",
       "338753    1.728765e-05\n",
       "338754    1.913312e-06\n",
       "Name: normalized_prev_number_of_plays, Length: 338755, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snd_df.normalized_prev_number_of_plays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class UserLogisticRegression(nn.Module):\n",
    "    def __init__(self, num_users):\n",
    "        super(UserLogisticRegression, self).__init__()\n",
    "        # Embedding layer to store coefficients for each user_id\n",
    "        self.user_coefficients = nn.Embedding(num_users, 2)\n",
    "        # Fixed constant\n",
    "        self.fixed_constant = 0.5\n",
    "\n",
    "    def forward(self, user_id, x):\n",
    "        \"\"\"\n",
    "        user_id: Tensor of shape (batch_size,) with user IDs\n",
    "        x: Tensor of shape (batch_size, 2) with input features\n",
    "        \"\"\"\n",
    "        # Get the coefficients for the given user_ids\n",
    "        user_coeffs = self.user_coefficients(user_id)\n",
    "        \n",
    "        # Compute the logit as dot product of user-specific coefficients and input features\n",
    "        logits = torch.sum(user_coeffs * x, dim=1) + self.fixed_constant\n",
    "        \n",
    "        return logits\n",
    "\n",
    "# Example usage\n",
    "num_users = 1000  # Example: 1000 unique user_ids\n",
    "model = UserLogisticRegression(num_users)\n",
    "\n",
    "# Example input data\n",
    "user_ids = torch.tensor([0, 1, 2])  # Example user IDs\n",
    "features = torch.tensor([[1.0, 2.0], [2.0, 3.0], [3.0, 4.0]])  # Example feature vectors\n",
    "\n",
    "# Forward pass\n",
    "logits = model(user_ids, features)\n",
    "print(logits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "\n",
    "class UserSongDataset(Dataset):\n",
    "    def __init__(self, user_song_data, all_songs, num_negatives=1):\n",
    "        \"\"\"\n",
    "        user_song_data: List of tuples (user_id, song_id, x1, x2, y) where y = 1 for positive samples\n",
    "        all_songs: List or set of all possible song_ids\n",
    "        num_negatives: Number of negative samples to generate per positive sample\n",
    "        \"\"\"\n",
    "        self.user_song_data = user_song_data\n",
    "        self.all_songs = list(all_songs)\n",
    "        self.num_negatives = num_negatives\n",
    "        \n",
    "        # Create a dictionary of user_id to set of song_ids for fast lookup\n",
    "        self.user_song_dict = {}\n",
    "        for user_id, song_id, _, _, _ in user_song_data:\n",
    "            if user_id not in self.user_song_dict:\n",
    "                self.user_song_dict[user_id] = set()\n",
    "            self.user_song_dict[user_id].add(song_id)\n",
    "        \n",
    "        # Precompute the dataset including negative samples\n",
    "        self.dataset = self._generate_dataset()\n",
    "\n",
    "    def _generate_dataset(self):\n",
    "        data = []\n",
    "        for user_id, song_id, x1, x2, y in self.user_song_data:\n",
    "            # Add the positive sample\n",
    "            data.append((user_id, song_id, x1, x2, y))\n",
    "            \n",
    "            # Generate negative samples\n",
    "            for _ in range(self.num_negatives):\n",
    "                negative_song_id = np.random.choice(self.all_songs)\n",
    "                while negative_song_id in self.user_song_dict[user_id]:\n",
    "                    negative_song_id = np.random.choice(self.all_songs)\n",
    "                data.append((user_id, negative_song_id, x1, x2, 0))  # y=0 for negative sample\n",
    "        \n",
    "        return data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        user_id, song_id, x1, x2, y = self.dataset[idx]\n",
    "        return torch.tensor(user_id), torch.tensor(song_id), torch.tensor([x1, x2], dtype=torch.float32), torch.tensor(y)\n",
    "\n",
    "# Example usage\n",
    "# Suppose we have the following positive data\n",
    "user_song_data = [\n",
    "    (0, 101, 0.5, 0.3, 1),\n",
    "    (0, 102, 0.6, 0.4, 1),\n",
    "    (1, 101, 0.7, 0.2, 1)\n",
    "]\n",
    "\n",
    "# And these are all possible song_ids\n",
    "all_songs = {101, 102, 103, 104}\n",
    "\n",
    "# Create the dataset with 2 negative samples per positive sample\n",
    "dataset = UserSongDataset(user_song_data, all_songs, num_negatives=2)\n",
    "\n",
    "# Create the DataLoader\n",
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)\n",
    "\n",
    "# Iterate over the DataLoader\n",
    "for batch in dataloader:\n",
    "    user_ids, song_ids, features, labels = batch\n",
    "    print(\"User IDs:\", user_ids)\n",
    "    print(\"Song IDs:\", song_ids)\n",
    "    print(\"Features:\", features)\n",
    "    print(\"Labels:\", labels)\n",
    "    print()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
