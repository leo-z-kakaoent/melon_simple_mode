{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e50d501c-9171-4afa-ab1d-bcf32e91a5b6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-20 00:39:47,696\tINFO worker.py:1841 -- Started a local Ray instance.\n",
      "UserWarning: Distributing <class 'pandas.core.frame.DataFrame'> object. This may take some time.\n",
      "UserWarning: Distributing <class 'pandas.core.frame.DataFrame'> object. This may take some time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: 'cuda'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: Found function 'dropout' with keyword argument 'training'. During FX tracing, this will likely be baked in as a constant value. Consider replacing this function by a module to properly encapsulate its training flag.\n",
      "UserWarning: Found function 'dropout_1' with keyword argument 'training'. During FX tracing, this will likely be baked in as a constant value. Consider replacing this function by a module to properly encapsulate its training flag.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import modin.pandas as mpd\n",
    "import random\n",
    "\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch import Tensor\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "from torch_geometric.loader import LinkNeighborLoader\n",
    "\n",
    "from torch_geometric.data import HeteroData\n",
    "import torch_geometric.transforms as T\n",
    "\n",
    "from torch_geometric.nn import GATConv, to_hetero\n",
    "import torch.nn.functional as F\n",
    "\n",
    "playlist_song = mpd.DataFrame(pd.read_parquet(\"data/gnn_playlists2songs.parquet\"))\n",
    "song_artist = mpd.DataFrame(pd.read_parquet(\"data/gnn_songs2artists.parquet\"))\n",
    "playlist_tag = mpd.DataFrame(pd.read_parquet(\"data/gnn_playlists2tags.parquet\"))\n",
    "\n",
    "unique_playlist_id = np.unique(playlist_song['playlist_id'].values)\n",
    "unique_playlist_id = mpd.DataFrame(data={\n",
    "    'playlist_id': unique_playlist_id,\n",
    "    'mappedID': pd.RangeIndex(len(unique_playlist_id)),\n",
    "})\n",
    "unique_song_id = np.unique(playlist_song['song_id'].values)\n",
    "unique_song_id = mpd.DataFrame(data={\n",
    "    'song_id': unique_song_id,\n",
    "    'mappedID': pd.RangeIndex(len(unique_song_id)),\n",
    "})\n",
    "unique_artist = np.unique(song_artist['artist_id'].values)\n",
    "unique_artist = mpd.DataFrame(data={\n",
    "    'artist': unique_artist,\n",
    "    'mappedID': pd.RangeIndex(len(unique_artist)),\n",
    "})\n",
    "unique_tag = np.unique(playlist_tag['tag_id'].values)\n",
    "unique_tag = mpd.DataFrame(data={\n",
    "    'tag': unique_tag,\n",
    "    'mappedID': pd.RangeIndex(len(unique_tag)),\n",
    "})\n",
    "\n",
    "def make_edge(edge_df, u0, u1):\n",
    "    edge_df.drop_duplicates(inplace=True)\n",
    "    ekey0, ekey1 = list(edge_df.columns)\n",
    "    ukey0 = u0.columns[0]\n",
    "    ukey1 = u1.columns[0]\n",
    "    temp0 = mpd.merge(edge_df[ekey0], u0, left_on=ekey0, right_on=ukey0, how='left')\n",
    "    temp0 = torch.from_numpy(temp0['mappedID'].values)\n",
    "    temp1 = mpd.merge(edge_df[ekey1], u1, left_on=ekey1, right_on=ukey1, how='left')\n",
    "    temp1 = torch.from_numpy(temp1['mappedID'].values)\n",
    "    return torch.stack([temp0, temp1], dim=0)\n",
    "\n",
    "edge_playlist_song = make_edge(playlist_song, unique_playlist_id, unique_song_id)\n",
    "edge_song_artist = make_edge(song_artist, unique_song_id, unique_artist)\n",
    "edge_playlist_tag = make_edge(playlist_tag, unique_playlist_id, unique_tag)\n",
    "\n",
    "data = HeteroData()\n",
    "\n",
    "data[\"playlist\"].node_id = torch.arange(len(unique_playlist_id))\n",
    "data[\"song\"].node_id = torch.arange(len(unique_song_id))\n",
    "data[\"artist\"].node_id = torch.arange(len(unique_artist))\n",
    "data[\"tag\"].node_id = torch.arange(len(unique_tag))\n",
    "\n",
    "data[\"playlist\", \"playlist2song\", \"song\"].edge_index = edge_playlist_song\n",
    "data[\"song\", \"song2artist\", \"artist\"].edge_index = edge_song_artist\n",
    "data[\"playlist\", \"playlist2tag\", \"tag\"].edge_index = edge_playlist_tag\n",
    "\n",
    "data = T.ToUndirected()(data)\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# device = torch.device('cpu')\n",
    "print(f\"Device: '{device}'\")\n",
    "\n",
    "from torch_geometric.nn import GATConv, to_hetero\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, heads=8):\n",
    "        super().__init__()\n",
    "        self.conv1 = GATConv(hidden_channels, hidden_channels, heads, dropout=0.6, add_self_loops=False)\n",
    "        self.conv2 = GATConv(hidden_channels * heads, hidden_channels, heads=1, dropout=0.6, add_self_loops=False)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = F.dropout(x, p=0.6, training=self.training)\n",
    "        x = F.elu(self.conv1(x, edge_index))\n",
    "        x = F.dropout(x, p=0.6, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "    \n",
    "class Classifier(torch.nn.Module):\n",
    "    def forward(self, x_playlist: Tensor, x_song: Tensor, edge_label_index: Tensor) -> Tensor:\n",
    "        edge_feat_playlist = x_playlist[edge_label_index[0]]\n",
    "        edge_feat_song = x_song[edge_label_index[1]]\n",
    "        return (edge_feat_playlist * edge_feat_song).sum(dim=-1)\n",
    "\n",
    "\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super().__init__()\n",
    "        self.playlist_emb = torch.nn.Embedding(data[\"playlist\"].num_nodes, hidden_channels)\n",
    "        self.song_emb = torch.nn.Embedding(data[\"song\"].num_nodes, hidden_channels)\n",
    "        self.tag_emb = torch.nn.Embedding(data[\"tag\"].num_nodes, hidden_channels)\n",
    "        self.artist_emb = torch.nn.Embedding(data[\"artist\"].num_nodes, hidden_channels)\n",
    "        self.gnn = GNN(hidden_channels)\n",
    "        self.gnn = to_hetero(self.gnn, metadata=data.metadata())\n",
    "        self.classifier = Classifier()\n",
    "\n",
    "    def forward(self, data: HeteroData) -> Tensor:\n",
    "        x_dict = {\n",
    "          \"playlist\": self.playlist_emb(data[\"playlist\"].node_id),\n",
    "          \"song\": self.song_emb(data[\"song\"].node_id),\n",
    "          \"artist\": self.artist_emb(data[\"artist\"].node_id),\n",
    "          \"tag\": self.tag_emb(data[\"tag\"].node_id),\n",
    "        } \n",
    "\n",
    "        x_dict = self.gnn(x_dict, data.edge_index_dict)\n",
    "        pred = self.classifier(\n",
    "            x_dict[\"playlist\"],\n",
    "            x_dict[\"song\"],\n",
    "            data[\"playlist\", \"playlist2song\", \"song\"].edge_label_index,\n",
    "        )\n",
    "\n",
    "        return pred\n",
    "\n",
    "        \n",
    "model = Model(hidden_channels=64)\n",
    "batch_size = 1024 * 4\n",
    "epochs = 1000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e09d564b-21f0-4bc1-a8bf-251e2e0beba4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pas = pd.read_csv(\"playlists.csv\")['playlist_id'].iloc[:50]\n",
    "model_name = \"model/nodes4_tag/epoch_0606.pth\"\n",
    "save_table_name = \"dev-ai-project-357507.leo_melon_temp.gnn_playlist_4nodes_tag\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9dc13313-2de1-4c91-ab78-ab5f906cd4b3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: Found function 'dropout' with keyword argument 'training'. During FX tracing, this will likely be baked in as a constant value. Consider replacing this function by a module to properly encapsulate its training flag.\n",
      "UserWarning: Found function 'dropout_1' with keyword argument 'training'. During FX tracing, this will likely be baked in as a constant value. Consider replacing this function by a module to properly encapsulate its training flag.\n"
     ]
    }
   ],
   "source": [
    "# model = Model(hidden_channels=64)\n",
    "old_model = torch.load(model_name, weights_only=False)\n",
    "state_dict = old_model.state_dict()\n",
    "\n",
    "model = Model(hidden_channels=64)\n",
    "model = model.to(device)\n",
    "model.load_state_dict(state_dict)\n",
    "_ = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2fed418-02fa-4ae3-b736-065e2ce80721",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [07:03<00:00,  8.47s/it]\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import bigquery\n",
    "\n",
    "# Initialize a BigQuery client\n",
    "client = bigquery.Client()\n",
    "\n",
    "# Define your table ID\n",
    "table_id = save_table_name\n",
    "\n",
    "for pa in tqdm(pas):\n",
    "    pa_id = unique_playlist_id.loc[unique_playlist_id['playlist_id'] == pa]['mappedID'].item()\n",
    "\n",
    "    songsin = edge_playlist_song[1][torch.where(edge_playlist_song[0] == pa_id)]\n",
    "\n",
    "    all_songs = torch.arange(len(model.song_emb.weight))\n",
    "    target_songs = all_songs[~torch.isin(all_songs, songsin)]\n",
    "    playlist_song_pairs = torch.cartesian_prod(torch.tensor([pa_id]), target_songs)\n",
    "\n",
    "    # Step 3: Create a LinkNeighborLoader\n",
    "    link_loader = LinkNeighborLoader(\n",
    "        data=data,\n",
    "        num_neighbors=[32, 16],  # Number of neighbors to sample at each hop\n",
    "        edge_label_index=((\"playlist\", \"playlist2song\", \"song\"), playlist_song_pairs.T),\n",
    "        batch_size=batch_size,  # Number of pairs per batch\n",
    "        shuffle=False,  # Shuffle the data for better training\n",
    "        num_workers=0,\n",
    "    )\n",
    "    for sampled_data in link_loader:\n",
    "\n",
    "        sampled_data.to(device)\n",
    "        preds = model(sampled_data).detach().cpu().numpy()\n",
    "        edge_label_index = sampled_data[\"playlist\", \"playlist2song\", \"song\"].edge_label_index.cpu().numpy()\n",
    "        playlists = sampled_data['playlist'].node_id[edge_label_index[0]].cpu().numpy()\n",
    "        songs = sampled_data['song'].node_id[edge_label_index[1]].cpu().numpy()\n",
    "        temp_song_ids = unique_song_id.loc[songs].song_id\n",
    "        rows_to_insert = [\n",
    "            {\"source_playlist_id\": int(pa), \n",
    "             \"song_id\": int(tsi),\n",
    "             \"prediction\": float(p)} for tsi, p in zip(temp_song_ids, preds) if p > 3]  \n",
    "        if len(rows_to_insert) > 0:\n",
    "            errors = client.insert_rows_json(table_id, rows_to_insert)\n",
    "            if errors:\n",
    "                print(\"Errors:\", errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b703c235-2e4a-4e73-955b-e128faca4a34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m128",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m128"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
