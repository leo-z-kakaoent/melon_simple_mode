{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "970b7273-8d80-4779-bd7a-f517c3a3ed7f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import modin.pandas as mpd\n",
    "import random\n",
    "\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch import Tensor\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "from torch_geometric.loader import LinkNeighborLoader\n",
    "\n",
    "from torch_geometric.data import HeteroData\n",
    "import torch_geometric.transforms as T\n",
    "\n",
    "from torch_geometric.nn import GATConv, to_hetero\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e414a7e-a5be-4181-b8b7-bf1642c97e86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "savefd = \"model/nodes4_tag/\"\n",
    "os.makedirs(savefd, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b26e220e-c5c6-4dc2-8372-50a8af9b551f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-20 00:52:25,136\tINFO worker.py:1841 -- Started a local Ray instance.\n",
      "UserWarning: Distributing <class 'pandas.core.frame.DataFrame'> object. This may take some time.\n",
      "UserWarning: Distributing <class 'pandas.core.frame.DataFrame'> object. This may take some time.\n"
     ]
    }
   ],
   "source": [
    "playlist_song = mpd.DataFrame(pd.read_parquet(\"data/gnn_playlists2songs.parquet\"))\n",
    "song_artist = mpd.DataFrame(pd.read_parquet(\"data/gnn_songs2artists.parquet\"))\n",
    "playlist_tag = mpd.DataFrame(pd.read_parquet(\"data/gnn_playlists2tags.parquet\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9182fb1c-0917-4d5c-8863-99e8bccabf15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "unique_playlist_id = np.unique(playlist_song['playlist_id'].values)\n",
    "unique_playlist_id = mpd.DataFrame(data={\n",
    "    'playlist_id': unique_playlist_id,\n",
    "    'mappedID': pd.RangeIndex(len(unique_playlist_id)),\n",
    "})\n",
    "unique_song_id = np.unique(playlist_song['song_id'].values)\n",
    "unique_song_id = mpd.DataFrame(data={\n",
    "    'song_id': unique_song_id,\n",
    "    'mappedID': pd.RangeIndex(len(unique_song_id)),\n",
    "})\n",
    "unique_artist = np.unique(song_artist['artist_id'].values)\n",
    "unique_artist = mpd.DataFrame(data={\n",
    "    'artist': unique_artist,\n",
    "    'mappedID': pd.RangeIndex(len(unique_artist)),\n",
    "})\n",
    "unique_tag = np.unique(playlist_tag['tag_id'].values)\n",
    "unique_tag = mpd.DataFrame(data={\n",
    "    'tag': unique_tag,\n",
    "    'mappedID': pd.RangeIndex(len(unique_tag)),\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "595623bb-d713-442c-bc13-dc34e91e5b0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_edge(edge_df, u0, u1):\n",
    "    edge_df.drop_duplicates(inplace=True)\n",
    "    ekey0, ekey1 = list(edge_df.columns)\n",
    "    ukey0 = u0.columns[0]\n",
    "    ukey1 = u1.columns[0]\n",
    "    temp0 = mpd.merge(edge_df[ekey0], u0, left_on=ekey0, right_on=ukey0, how='left')\n",
    "    temp0 = torch.from_numpy(temp0['mappedID'].values)\n",
    "    temp1 = mpd.merge(edge_df[ekey1], u1, left_on=ekey1, right_on=ukey1, how='left')\n",
    "    temp1 = torch.from_numpy(temp1['mappedID'].values)\n",
    "    return torch.stack([temp0, temp1], dim=0)\n",
    "\n",
    "edge_playlist_song = make_edge(playlist_song, unique_playlist_id, unique_song_id)\n",
    "edge_song_artist = make_edge(song_artist, unique_song_id, unique_artist)\n",
    "edge_playlist_tag = make_edge(playlist_tag, unique_playlist_id, unique_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82b5f485-1f9e-423a-b237-b1935a5f0b3a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = HeteroData()\n",
    "\n",
    "data[\"playlist\"].node_id = torch.arange(len(unique_playlist_id))\n",
    "data[\"song\"].node_id = torch.arange(len(unique_song_id))\n",
    "data[\"artist\"].node_id = torch.arange(len(unique_artist))\n",
    "data[\"tag\"].node_id = torch.arange(len(unique_tag))\n",
    "\n",
    "data[\"playlist\", \"playlist2song\", \"song\"].edge_index = edge_playlist_song\n",
    "data[\"song\", \"song2artist\", \"artist\"].edge_index = edge_song_artist\n",
    "data[\"playlist\", \"playlist2tag\", \"tag\"].edge_index = edge_playlist_tag\n",
    "\n",
    "data = T.ToUndirected()(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd37c826-6319-4c95-b962-064cc7c7c150",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: Found function 'dropout' with keyword argument 'training'. During FX tracing, this will likely be baked in as a constant value. Consider replacing this function by a module to properly encapsulate its training flag.\n",
      "UserWarning: Found function 'dropout_1' with keyword argument 'training'. During FX tracing, this will likely be baked in as a constant value. Consider replacing this function by a module to properly encapsulate its training flag.\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.nn import GATConv, to_hetero\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, heads=8):\n",
    "        super().__init__()\n",
    "        self.conv1 = GATConv(hidden_channels, hidden_channels, heads, dropout=0.6, add_self_loops=False)\n",
    "        self.conv2 = GATConv(hidden_channels * heads, hidden_channels, heads=1, dropout=0.6, add_self_loops=False)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = F.dropout(x, p=0.6, training=self.training)\n",
    "        x = F.elu(self.conv1(x, edge_index))\n",
    "        x = F.dropout(x, p=0.6, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "    \n",
    "class Classifier(torch.nn.Module):\n",
    "    def forward(self, x_playlist: Tensor, x_song: Tensor, edge_label_index: Tensor) -> Tensor:\n",
    "        edge_feat_playlist = x_playlist[edge_label_index[0]]\n",
    "        edge_feat_song = x_song[edge_label_index[1]]\n",
    "        return (edge_feat_playlist * edge_feat_song).sum(dim=-1)\n",
    "\n",
    "\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super().__init__()\n",
    "        self.playlist_emb = torch.nn.Embedding(data[\"playlist\"].num_nodes, hidden_channels)\n",
    "        self.song_emb = torch.nn.Embedding(data[\"song\"].num_nodes, hidden_channels)\n",
    "        self.tag_emb = torch.nn.Embedding(data[\"tag\"].num_nodes, hidden_channels)\n",
    "        self.artist_emb = torch.nn.Embedding(data[\"artist\"].num_nodes, hidden_channels)\n",
    "        self.gnn = GNN(hidden_channels)\n",
    "        self.gnn = to_hetero(self.gnn, metadata=data.metadata())\n",
    "        self.classifier = Classifier()\n",
    "\n",
    "    def forward(self, data: HeteroData) -> Tensor:\n",
    "        x_dict = {\n",
    "          \"playlist\": self.playlist_emb(data[\"playlist\"].node_id),\n",
    "          \"song\": self.song_emb(data[\"song\"].node_id),\n",
    "          \"artist\": self.artist_emb(data[\"artist\"].node_id),\n",
    "          \"tag\": self.tag_emb(data[\"tag\"].node_id),\n",
    "        } \n",
    "\n",
    "        x_dict = self.gnn(x_dict, data.edge_index_dict)\n",
    "        pred = self.classifier(\n",
    "            x_dict[\"playlist\"],\n",
    "            x_dict[\"song\"],\n",
    "            data[\"playlist\", \"playlist2song\", \"song\"].edge_label_index,\n",
    "        )\n",
    "\n",
    "        return pred\n",
    "\n",
    "        \n",
    "model = Model(hidden_channels=64)\n",
    "batch_size = 1024 * 4\n",
    "epochs = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9311e057-b317-4c06-8c79-0a643791438d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch_geometric.loader import LinkNeighborLoader\n",
    "\n",
    "transform = T.RandomLinkSplit(\n",
    "    num_val=0,\n",
    "    num_test=0,\n",
    "    disjoint_train_ratio=0,\n",
    "    neg_sampling_ratio=2.0,\n",
    "    add_negative_train_samples=False,\n",
    "    edge_types=(\"playlist\", \"playlist2song\", \"song\"),\n",
    "    rev_edge_types=(\"song\", \"rev_playlist2song\", \"playlist\"), \n",
    ")\n",
    "\n",
    "train_data, val_data, test_data = transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c487f6ef-7b80-48e3-b827-fbd07d1e8c3e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_loader = LinkNeighborLoader(\n",
    "    data=train_data,\n",
    "    num_neighbors=[32, 16],\n",
    "    neg_sampling_ratio=2.0,\n",
    "    edge_label_index=((\"playlist\", \"playlist2song\", \"song\"), train_data[\"playlist\", \"playlist2song\", \"song\"].edge_label_index),\n",
    "    edge_label=train_data[\"playlist\", \"playlist2song\", \"song\"].edge_label,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e3ef693-738d-46e6-8b46-7fe07b559e07",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (785082875.py, line 19)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[10], line 19\u001b[0;36m\u001b[0m\n\u001b[0;31m    optimizer.zero_grad()u\u001b[0m\n\u001b[0m                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: '{device}'\")\n",
    "\n",
    "model_name = \"model/nodes4_tag/epoch_0606.pth\"\n",
    "model = model.to(device)\n",
    "old_model = torch.load(model_name, weights_only=False)\n",
    "state_dict = old_model.state_dict()\n",
    "model.load_state_dict(state_dict)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "pbar = tqdm(total=epochs*len(train_loader))\n",
    "for epoch in range(epochs):\n",
    "    total_loss = total_examples = 0\n",
    "    model.train()\n",
    "    for sampled_data in train_loauuuuder:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        sampled_data.to(device)\n",
    "        pred = model(sampled_data)\n",
    "\n",
    "        ground_truth = sampled_data[\"playlist\", \"playlist2song\", \"song\"].edge_label\n",
    "        loss = F.binary_cross_entropy_with_logits(pred, ground_truth)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        pbar.update(1)\n",
    "    \n",
    "    filename = f\"{savefd}/epoch_2_{str(epoch).zfill(4)}.pth\"\n",
    "    torch.save(model, filename)\n",
    "    pbar.set_description(f\"Epoch: {epoch}\")\n",
    "    # print(filename, \" saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288f11d9-170c-406c-bcfd-4b973bc42647",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m128",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m128"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
